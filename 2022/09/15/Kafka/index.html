<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.0.0-rc2">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"dangyoo.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="闲言碎语没啥好说的，Kafka算是每个公司都会用到的东西了吧，虽然知道是消息队列，但具体怎么队列的，和其他的比如RabbitMQ有啥区别，确实不太懂。">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka">
<meta property="og:url" content="https://dangyoo.github.io/2022/09/15/Kafka/index.html">
<meta property="og:site_name" content="西左Log">
<meta property="og:description" content="闲言碎语没啥好说的，Kafka算是每个公司都会用到的东西了吧，虽然知道是消息队列，但具体怎么队列的，和其他的比如RabbitMQ有啥区别，确实不太懂。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://dangyoo.github.io/images/kafka.png">
<meta property="article:published_time" content="2022-09-15T10:06:03.000Z">
<meta property="article:modified_time" content="2024-03-31T08:00:48.901Z">
<meta property="article:author" content="西左">
<meta property="article:tag" content="Data">
<meta property="article:tag" content="Kafka">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://dangyoo.github.io/images/kafka.png">

<link rel="canonical" href="https://dangyoo.github.io/2022/09/15/Kafka/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Kafka | 西左Log</title>
  


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?15db7c636ac845c8c8fe0ca45dac6e54";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">西左Log</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://dangyoo.github.io/2022/09/15/Kafka/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpeg">
      <meta itemprop="name" content="西左">
      <meta itemprop="description" content="自是者不彰。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="西左Log">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Kafka
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-09-15 18:06:03" itemprop="dateCreated datePublished" datetime="2022-09-15T18:06:03+08:00">2022-09-15</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%9F%A5%E8%AF%86/" itemprop="url" rel="index"><span itemprop="name">知识</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="闲言碎语"><a href="#闲言碎语" class="headerlink" title="闲言碎语"></a>闲言碎语</h2><p>没啥好说的，Kafka算是每个公司都会用到的东西了吧，虽然知道是消息队列，但具体怎么队列的，和其他的比如RabbitMQ有啥区别，确实不太懂。</p>
<span id="more"></span>

<h2 id="进程间的通信方式"><a href="#进程间的通信方式" class="headerlink" title="进程间的通信方式"></a>进程间的通信方式</h2><p>消息队列（Message queue）是一种进程间通信或同一进程的不同线程间的通信方式，除了消息队列，进程间的通信方式（Inter-Process Communication，简称IPC）还有：无名管道（pipe）、高级管道（popen）、有名管道（named pipe）、信号量（semophore）、共享内存（shared memory）、套接字（socket）</p>
<h3 id="无名管道"><a href="#无名管道" class="headerlink" title="无名管道"></a>无名管道</h3><p>管道是一种半双工的通信方式，数据只能同一时间单向流动，而且只能在具有亲缘关系的进程间使用，进程间的亲缘关系同化成那个指的是父子进程关系。</p>
<h4 id="半双工"><a href="#半双工" class="headerlink" title="半双工"></a>半双工</h4><p>半双工（Half Duplex）是指数据可以在一个信号载体的两个方向上传输，但是不能同时传输。全双工，即信息可以在两个方向上同时传输。单工则只能在一个方向传输。</p>
<h3 id="高级管道"><a href="#高级管道" class="headerlink" title="高级管道"></a>高级管道</h3><p>讲一个程序当做一个新的进程在当前程序进程中启动，则它算是当前进程的紫禁城，这种方式称之为高级管道。</p>
<h3 id="有名管道"><a href="#有名管道" class="headerlink" title="有名管道"></a>有名管道</h3><p>也是半双工通信方式，但允许无情缘关系的进程间通信。</p>
<h3 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h3><p>消息队列是消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息量烧、管道只能承载无格式字节流以及缓冲区大小受限等缺点。</p>
<h3 id="信号量"><a href="#信号量" class="headerlink" title="信号量"></a>信号量</h3><p>一个计数器，可以用来控制多个进程对共享资源的访问。常作为一个锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源导致冲突。</p>
<h3 id="共享内存"><a href="#共享内存" class="headerlink" title="共享内存"></a>共享内存</h3><p>指的是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的进程间通信方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制如信号量配合使用，来实现进程间的同步和通信。</p>
<h3 id="套接字"><a href="#套接字" class="headerlink" title="套接字"></a>套接字</h3><p>可以用于不同机器间的进程通信。</p>
<h2 id="消息队列-1"><a href="#消息队列-1" class="headerlink" title="消息队列"></a>消息队列</h2><p>Message Queue（MQ），屏蔽底层复杂的通讯协议，定义了一套应用层更加简单的通讯协议</p>
<p>一个分布式系统中的两个模块之间的通讯要么是HTTP，要么是自己开发的（rcp）TCP</p>
<p>HTTP协议很难实现两端通讯，即A调用B同时B也可以调用A，想要实现的话AB都需要WebServer ，而实现TCP则更加复杂</p>
<p>MQ做的就是在这些协议至上构建一个更高层次的、更简单的生产者&#x2F;消费者通讯模型，它定义了两个对象，发送数据的生产者和接收数据的消费者，并提供一个SDK来定义而这实现消息通讯而无视底层通讯协议</p>
<h3 id="一些相关概念"><a href="#一些相关概念" class="headerlink" title="一些相关概念"></a>一些相关概念</h3><h4 id="HTTP协议"><a href="#HTTP协议" class="headerlink" title="HTTP协议"></a>HTTP协议</h4><p>Hyper Text Transfer Protocal，超文本传输协议，是一个基于TCP&#x2F;IP通信协议来传递数据的协议，它工作于客户端-服务端架构上，客户端通过URL向服务端（WebServer）发送请求，服务端接收到请求后，向客户端发送响应信息</p>
<p>HTTP是无连接，即限制每次连接只能处理一个请求，服务器处理完客户的请求并收到客户的应答后，即断开连接，采用这种方式可以节省传输时间</p>
<p>HTTP是媒体独立的，即只要客户端和服务器知道如何处理数据内容，任何类型的数据都可以通过HTTP发送，客户端及服务器指定使用合适的MIME-type内容类型</p>
<p>HTTP是无状态协议，指协议对于事务处理没有记忆能力，缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大，另一方面，在服务器不需要先前信息时它的应答就较快</p>
<h4 id="MIME"><a href="#MIME" class="headerlink" title="MIME"></a>MIME</h4><p>Multipurpose Internet Main Extensions，描述消息内容类型的标准，用来标识文档、文件或字节流的性质和格式，浏览器通常使用MIME类型来确定如何处理URL，因此WebServer在响应头中添加正确的MIME类型非常重要，如果配置不正确，浏览器可能会无法解析文件内容，网站将无法正常工作，下载的文件也会被错误处理</p>
<p>MIME类型通用结构为type&#x2F;subtype，常见的有</p>
<p>text&#x2F;html -&gt; 超文本标记语言文本</p>
<p>text&#x2F;plain -&gt; 普通文本</p>
<p>imge&#x2F;gif -&gt; GIF图形</p>
<h4 id="RCP"><a href="#RCP" class="headerlink" title="RCP"></a>RCP</h4><p>Remote Copy，远程复制，是在Unix操作系统中用于在计算机之间远程复制一个或多个文件的命令，通过TCP&#x2F;IP协议传输，已经被更安全的协议和命令所渠道，如SCP（基于安全Shell的安全副本）和SFTP（简单文件传输协议）</p>
<h4 id="TCP-IP"><a href="#TCP-IP" class="headerlink" title="TCP&#x2F;IP"></a>TCP&#x2F;IP</h4><p>Transmission Control Protocol&#x2F;Internet Protocol，传输控制协议&#x2F;网际协议，定义了电子设备如何连入因特网，以及数据如何在它们之间传输</p>
<p>TCP&#x2F;IP中包含一系列用于处理数据通信的协议，如TCP用于应用程序之间的通信，UDP（用户数据报协议）用于应用程序之间的简单通信，IP用于计算机之间的通信，ICMP（因特网消息控制协议）是针对错误和状态的通信，DHCP（动态主机配置协议）是针对动态寻址的协议</p>
<p>TCP负责将应用程序的数据分割并装入IP包，然后在到达的时候重新组合它们，而IP则负责将包发送给接受者</p>
<h4 id="SDK"><a href="#SDK" class="headerlink" title="SDK"></a>SDK</h4><p>Software Development Kit，软件开发工具包，即可用于开发面向特定平台软件应用程序的工具包，类似于Python中的TensorFlow包，就是谷歌提供的TensorFlow对应的SDK</p>
<h3 id="消息队列的分类"><a href="#消息队列的分类" class="headerlink" title="消息队列的分类"></a>消息队列的分类</h3><h4 id="有Broker的MQ"><a href="#有Broker的MQ" class="headerlink" title="有Broker的MQ"></a>有Broker的MQ</h4><p>有服务器作为Broker，所有消息都通过它中转，生产者把消息发送给Broker就结束了自己的任务，Broker着把消息主动推送给消费者或等待消费者主动轮询</p>
<h5 id="重Topic"><a href="#重Topic" class="headerlink" title="重Topic"></a>重Topic</h5><p>Kafka、ActiveMQ（JMS）属于重Topic类型，生产者会发送key和数据到Broker，由Broker比较key之后决定给哪个消费者消费</p>
<p>在这种模式下，一个topc往往是一个较大的概念，甚至一个系统中可能只有一个topic，topic某种意义上就是queue</p>
<p>虽然架构一致，但Kafka的性能比ActiveMQ高很多，所以这种类型的MQ只有Kafka一种备选方案</p>
<p>RocketMQ是阿里基于Kafka重写的，保证消息必答而牺牲了性能，Kafka单机写入在百万条&#x2F;秒，而RocketMQ则在7万条&#x2F;秒，更适用于业务处理，而Kafka更适用于日志处理</p>
<h5 id="轻Topic"><a href="#轻Topic" class="headerlink" title="轻Topic"></a>轻Topic</h5><p>RabbitMQ（AMQP）属于轻Topic类型，生产者发送key和数据，消费者定义订阅的队列，Broker收到数据之后会通过一定的逻辑计算出key对应的队列，然后把数据交个队列</p>
<p>这种模式下解耦了key和queue，这种架构中queue是非常轻量级的，消费者只关心自己的queue，生产者不用关心数据最终给谁只要指定key就行，中间的映射层在AMQP中称为Exchange交换机</p>
<p>AMQP中有四种Exchange，分别是</p>
<ul>
<li>Direct exchange：key等于queue</li>
<li>Fanout exchange：无视key，给所有queue都来一份</li>
<li>Topic exchange：key可以模糊匹配queue</li>
<li>Headers exchange：无视key，通过查看消息头部元数据来决定发给哪个queue</li>
</ul>
<h4 id="无Broker的MQ"><a href="#无Broker的MQ" class="headerlink" title="无Broker的MQ"></a>无Broker的MQ</h4><p>ZeroMQ被设计成了一个库，而非中间件，更加轻量和灵活</p>
<p>节点之间通讯的消息都发送到彼此的队列中，每个节点都既是生产者优势消费者，ZeroMQ做的就是封装出一套类似于Socket的API来完成发送、读取数据</p>
<h3 id="消息队列的优势"><a href="#消息队列的优势" class="headerlink" title="消息队列的优势"></a>消息队列的优势</h3><ol>
<li>解耦：允许你独立地扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束；</li>
<li>可恢复性：系统的一部分组件失效时，不会影响到整个系统；</li>
<li>缓冲：有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致情况；</li>
<li>灵活性&amp;峰值处理能力：削峰，能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷请求而完全崩溃；</li>
<li>异步通信：提供异步处理机制，允许用户把消息放入队列，而不去处理，在想要去处理的时候再去处理。</li>
</ol>
<h3 id="消息队列的两种模式"><a href="#消息队列的两种模式" class="headerlink" title="消息队列的两种模式"></a>消息队列的两种模式</h3><ol>
<li>点对点模式<br>一对一，消费者主动拉取数据，消息收到后消息清除。<br>消息生产者生产消息发送到队列中，然后消息消费者从队列中取出并且消费消息。消息被消费后，队列中不再有存储，所以消息消费者不可能消费到已经被消费的消息。</li>
<li>发布&#x2F;订阅模式<br>一对多，消费者消费数据之后不会清除消息。 消息生产者将消息发布到topic（队列）中，同时有多个信息消费者（订阅）消费该消息，根据消费方式不同又分为两种：<ul>
<li>消费者主动订阅（Kafka的模式），消费者的消费速度由消费者自己定义，但需要轮询topic中是否有新消息；</li>
<li>队列主动推送（RabbitMQ的模式）。</li>
</ul>
</li>
</ol>
<h2 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h2><p>Kafka最初由Linkedin公司开发，是一个分布式的、支持分区（partition）的、多副本（replica）的，基于Zookeeper协调的发布&#x2F;订阅模式的消息系统，它最大的特性就是可以实时处理大量数据以满足各种需求场景，如基于Hadoop的批处理系统、低延迟的实时系统、Storm&#x2F;Flink流式处理引擎、Web&#x2F;Nginx日志、访问日志、消息服务等，用Scala编写。</p>
<h3 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h3><ul>
<li>日志收集：用Kafka来收集各种服务的Log，通过Kafka以统一接口服务的方式开放给各种消费者</li>
<li>消息系统：解耦生产者和消费者，缓存消息</li>
<li>用户活动跟踪：记录Web用户或者App用户的各种活动，如浏览网页、搜索、点击等，这些活动信息被各个服务器发布到Kafka的Topic中，然后消费者通过订阅这些Topic来做实时的监控分析，或者装载到Hadoop进行离线分析和挖掘</li>
<li>运营指标：Kafka也经常用来记录运营监控数据，包括收集各种分布式应用的数据，生产各种操作的集中反馈，例如报警或警告</li>
</ul>
<h3 id="搭建"><a href="#搭建" class="headerlink" title="搭建"></a>搭建</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载包，基于Scala2.13构建的最新3.5.1版本</span></span><br><span class="line">wget https://downloads.apache.org/kafka/3.5.1/kafka_2.13-3.5.1.tgz</span><br><span class="line">tar -zxvf kafka_2.13-3.5.1.tgz</span><br><span class="line"><span class="built_in">cd</span> kafka_2.13-3.5.1/config/</span><br><span class="line"><span class="comment"># 编辑服务端配置文件</span></span><br><span class="line">vim server.properties</span><br><span class="line"><span class="comment"># listeners=PLAINTEXT://localhost:9092  # 服务器地址和监听端口</span></span><br><span class="line"><span class="comment"># log.dirs=xxx  存储日志文件的地址</span></span><br><span class="line"><span class="comment"># zookeeper.connet=localhost:2181  # 所需连接的Zookeeper端口</span></span><br><span class="line"><span class="comment"># 后台启动</span></span><br><span class="line"><span class="built_in">cd</span> ../bin</span><br><span class="line">./kafka-server-start.sh -daemon ../config/server.properties</span><br><span class="line"><span class="comment"># 检查是否启动成功</span></span><br><span class="line">ps -aux | grep server.properties</span><br></pre></td></tr></table></figure>

<h3 id="基本架构"><a href="#基本架构" class="headerlink" title="基本架构"></a>基本架构</h3><img src="/images/kafka.png" width="50%" height="50%">

<h4 id="Broker"><a href="#Broker" class="headerlink" title="Broker"></a>Broker</h4><p>一台Kafka服务器就是一个Broker，一个集群由多个Broker组成，每个Broker可以容纳多个Topic</p>
<h4 id="Producer"><a href="#Producer" class="headerlink" title="Producer"></a>Producer</h4><p>消息生产者，将消息push到Kafka集群中的Broker</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动一个Producer，向Topic-test发送消息</span></span><br><span class="line">./kafka-console-producer.sh --broker-list localhost:9092 --topic <span class="built_in">test</span></span><br></pre></td></tr></table></figure>

<h4 id="Consumer"><a href="#Consumer" class="headerlink" title="Consumer"></a>Consumer</h4><p>消息消费者，从Kafka集群中pull消息，消费消息</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动一个Consumer，消费Topic-test的消息</span></span><br><span class="line"><span class="comment"># 从最后一条消息的偏移量+1开始消费</span></span><br><span class="line">./kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic <span class="built_in">test</span></span><br><span class="line"><span class="comment"># 从头开始消费</span></span><br><span class="line">./kafka-console-consumer.sh \</span><br><span class="line">--bootstrap-server localhost:9092 \</span><br><span class="line">--from-beginning \</span><br><span class="line">--topic <span class="built_in">test</span></span><br></pre></td></tr></table></figure>

<h4 id="Topic"><a href="#Topic" class="headerlink" title="Topic"></a>Topic</h4><p>消息的类别或者主题，逻辑上可以理解为队列。Producer只关注push消息到哪个Topic，Consumer只关注订阅了哪个Topic</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建Topic-test，只有一个分区，备份也是一个</span></span><br><span class="line">./kafka-topics.sh --create \</span><br><span class="line">--bootstrap-server localhost:9092 \</span><br><span class="line">--replication-factor 1 \</span><br><span class="line">--partitions 1 \</span><br><span class="line">--topic <span class="built_in">test</span></span><br><span class="line"><span class="comment"># Created topic test.</span></span><br><span class="line"><span class="comment"># 列出所有Topic</span></span><br><span class="line">./kafka-topics.sh --list --bootstrap-server localhost:9092</span><br><span class="line"><span class="comment"># test</span></span><br><span class="line"><span class="comment"># 查看test主题的信息</span></span><br><span class="line">./kafka-topics.sh --describe --topic <span class="built_in">test</span> --bootstrap-server localhost:9092</span><br><span class="line"><span class="comment"># Topic: test     TopicId: VjYQwUnxSquIDuoHR3HbsQ PartitionCount: 1       ReplicationFactor: 1    Configs: </span></span><br><span class="line"><span class="comment"># Topic: test     Partition: 0    Leader: 0       Replicas: 0     Isr: 0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.0以下的版本，Topic交给Zookeeper管理</span></span><br><span class="line"><span class="comment"># 创建Topic-test，只有一个分区，备份也是一个</span></span><br><span class="line">./kafka-topics.sh --create </span><br><span class="line">--zookeeper localhost:2181 \</span><br><span class="line">--replication-factor 1 \</span><br><span class="line">--partitions 1 \</span><br><span class="line">--topic <span class="built_in">test</span></span><br><span class="line"><span class="comment"># 列出所有Topic</span></span><br><span class="line">./kafka-topics.sh --list --zookeeper localhost:2181</span><br></pre></td></tr></table></figure>

<h4 id="Consumer-Group"><a href="#Consumer-Group" class="headerlink" title="Consumer Group"></a>Consumer Group</h4><p>消费者组，由一到多个Consumer组成，每个Consumer都属于一个Consumer Group，消费者组在逻辑上是一个订阅者。</p>
<p>消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费，消费者组之间互不影响。即每条消息只能被Consumer Group中的一个Consumer消费，但是可以被多个Consumer Group组消费，这样就实现了单播和多播。</p>
<p>消费者组的存在提高了同一个Topic的消费能力</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个消费者组中的消费者</span></span><br><span class="line">./kafka-console-consumer.sh --bootstrap-server localhost:9092 \</span><br><span class="line">--consumer-property group.id=testGroup \</span><br><span class="line">--topic <span class="built_in">test</span></span><br><span class="line"><span class="comment"># 查看消费者组的信息</span></span><br><span class="line">./kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list</span><br><span class="line"><span class="comment"># testGroup</span></span><br><span class="line"><span class="comment"># 查看某个消费者组的信息</span></span><br><span class="line">./kafka-consumer-groups.sh --bootstrap-server localhost:9092 \</span><br><span class="line">--describe --group testGroup</span><br><span class="line"><span class="comment"># GROUP           TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                           HOST            CLIENT-ID</span></span><br><span class="line"><span class="comment"># testGroup       test            0          5               5               0               console-consumer-fe47d017-2097-439e-9534-f0bf4b409345 /127.0.0.1      console-consumer</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># CURRENT-OFFSET：该TOPIC被该消费者组消费的最新OFFSET</span></span><br><span class="line"><span class="comment"># LOG-END-OFFSET：该TOPIC最新消息OFFSET</span></span><br><span class="line"><span class="comment"># LAG：LOG-END-OFFSET - CURRENT-OFFSET：多少消息没被消费</span></span><br></pre></td></tr></table></figure>
<p>单播 - 同一条消息只能被同一个消费者组中的一个消费者消费</p>
<p>多播 - 同一条消息能被不同消费者组中的不同消费者消费</p>
<h4 id="Partition"><a href="#Partition" class="headerlink" title="Partition"></a>Partition</h4><p>负载均衡与扩展性考虑，一个Topic可以分为多个Partition，物理存储在Kafka集群中的多个Broker上。可靠性上考虑，每个Partition都会有备份Replica</p>
<p>Kafka只能在Partition范围内保证消息的局部顺序性，而不能在同一个Topic中的多个Partition中保证总的消费顺序性</p>
<p>Consumer会定期将自己消费分区的offset提交给Kafka内置的topic：__consumer_offsets，提交过去的时候，key是Consumer Group+topic+分区号，value是当前的offset值，Kafka会定期清理topic里的消息，最后就保留最新的那条数据</p>
<p>因为__consumer_offsets可能会接收高并发的请求，Kafka默认分配50个分区（可以通过offsets.topic.num.partition设置）</p>
<p>通过公式（ hash(consumerGroupId)%__consumer_offsets的分区数 ）可以计算Consumer消费的offset要提交到__consumer_offsets的哪个分区</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">./kafka-topics.sh --create </span><br><span class="line">--bootstrap-server localhost:9092 \</span><br><span class="line">--replication-factor 1 \</span><br><span class="line">--partitions 2 \  <span class="comment"># 声明多个分区</span></span><br><span class="line">--topic test1</span><br><span class="line"><span class="comment"># 创建的保存Log的文件夹名为test1-0\test1-1</span></span><br><span class="line"><span class="comment"># .index存储的是数据offset索引</span></span><br><span class="line"><span class="comment"># .timeindex存储的是时间索引</span></span><br><span class="line"><span class="comment"># .log存储的是具体数据</span></span><br></pre></td></tr></table></figure>

<h4 id="Replica"><a href="#Replica" class="headerlink" title="Replica"></a>Replica</h4><p>Partition的副本，为了保证集群中的某个节点发生故障时，该节点上的Partition数据不会丢失，且Kafka仍能继续工作，所以Kafka提供了副本机制，一个Topic的每个Partition都有若干个副本，一个Leader和若干个Follower</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">./kafka-topics.sh --create </span><br><span class="line">--bootstrap-server localhost:9092 \</span><br><span class="line">--replication-factor 3 \  <span class="comment"># 声明3个副本</span></span><br><span class="line">--partitions 2 \  <span class="comment"># 声明多个分区</span></span><br><span class="line">--topic test2</span><br><span class="line"><span class="comment"># ./kafka-topics.sh --describe --topic test2 --bootstrap-server localhost:9092</span></span><br><span class="line"><span class="comment"># Topic：test2		partitionCount: 2		ReplicationFactor: 3		configs:</span></span><br><span class="line"><span class="comment">#	Topic: test2		Partition: 0		Leader: 2		Replicas: 2,0,1		Isr: 2,0,1</span></span><br><span class="line"><span class="comment"># Topic: test2    Partition: 1		Leader: 0		Replicas: 0,1,2   Isr: 0,1,2</span></span><br></pre></td></tr></table></figure>

<h4 id="Leader"><a href="#Leader" class="headerlink" title="Leader"></a>Leader</h4><p>Replica的主角色，Producer与Consumer只跟Leader交互</p>
<h4 id="Follower"><a href="#Follower" class="headerlink" title="Follower"></a>Follower</h4><p>Replica的从角色，实时从Leader中同步数据，保持和Leader数据的同步。Leader发生故障时，某个Follower会变成新的Leader</p>
<h4 id="Controller"><a href="#Controller" class="headerlink" title="Controller"></a>Controller</h4><p>Kafka集群中的其中一台服务器，用来进行Leader election以及各种Failover（故障转移），每个Broker启动时会向Zookeeper创建一个临时序号节点，序号最小的节点将作为集群的Controller</p>
<ul>
<li>当某个分区的Leader副本出现故障时，由Controller负责为该分区选举新的Leader</li>
<li>当检测到某个分区的ISR集合发生变化时，由Controller负责通知所有的Broker更新其元数据信息</li>
<li>当使用Kafka-topics.sh脚本为某个Topic增加分区数量时，由Controller负责让新分区被其他节点感知到</li>
</ul>
<h4 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h4><p>Kafka通过Zookeeper存储集群的meta等信息（0.9版本之后消费者的offset信息粗处在Kafka系统中）</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进入Zookeeper客户端下</span></span><br><span class="line">./zkCli.sh</span><br><span class="line"><span class="built_in">ls</span> /</span><br><span class="line"><span class="comment"># [admin, brokers, cluster, config, consumers, </span></span><br><span class="line"><span class="comment"># controller, controller_epoch, feature, </span></span><br><span class="line"><span class="comment"># isr_change_notification, latest_producer_id_block, log_dir_event_notification]</span></span><br><span class="line"><span class="comment"># 说明已经成功连接Zookeeper服务</span></span><br><span class="line"><span class="built_in">ls</span> /brokers</span><br><span class="line"><span class="comment"># [ids, seqid, topics]</span></span><br><span class="line"><span class="built_in">ls</span> /brokers/ids</span><br><span class="line"><span class="comment"># [0]</span></span><br></pre></td></tr></table></figure>

<h3 id="搭建集群"><a href="#搭建集群" class="headerlink" title="搭建集群"></a>搭建集群</h3><p>修改server.properties中的配置项</p>
<p>broker.id，listeners，log.dir</p>
<p>启动所有节点</p>
<h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><h4 id="ACK"><a href="#ACK" class="headerlink" title="ACK"></a>ACK</h4><p>Kafka服务端接收到Producer消息之后，返回已接收到的消息元数据</p>
<p>配置ack &#x3D; 0时，Producer只要把消息发送出去，Kafka就会返回ACK</p>
<p>配置ack &#x3D; 1时，Producer发送消息到Leader之后，Leader把消息写入到本地文件中，然后返回ACK</p>
<p>配置ack &#x3D; -1或all时，Producer发送消息到Leader之后，Leader把消息写入到本地文件，且数据被同步到（min.insync.replicas&#x3D;1）台Follower中后，才会返回ACK</p>
<h4 id="Batch"><a href="#Batch" class="headerlink" title="Batch"></a>Batch</h4><p>Producer处会生成一个缓冲区（Buffer Memory 默认32M），消息先进入缓冲区中，另外存在一个本地线程去缓冲区中拉取一定大小（Batch Size 默认16K）的数据，缓冲区数据小于16K时，每隔一定时间（Linger ms 默认10ms）拉取剩余数据，发送到Kafka中</p>
<h4 id="Offset"><a href="#Offset" class="headerlink" title="Offset"></a>Offset</h4><p>Consumer消费消息时，会去Kafka服务端的Topic中拉取（poll）一定长度的消息到Consumer所在服务器，如果设置为自动提交offset，则在消息拉取回来后，不管消息是否已经被消费，就会将offset提交到Kafka服务端，也就是说，自动提交是有可能造成消息丢失的</p>
<p>另一种设置是手动提交offset，指的是Consumer消费完信息后再进行提交，细节又分为两种</p>
<ul>
<li>手动同步提交：消费线程在offset提交前会一直阻塞</li>
<li>手动异步提交：消费线程不会因为offset提交未完成而阻塞</li>
</ul>
<h3 id="核心机制"><a href="#核心机制" class="headerlink" title="核心机制"></a>核心机制</h3><h4 id="ISR"><a href="#ISR" class="headerlink" title="ISR"></a>ISR</h4><p>In-Sync Replicas，指所有与Leader保持一定程度（可配置时间&#x2F;准确度）同步的副本（包括Leader自己），Leader负责维护和跟踪ISR集合中所有Follower的之后状态，当某个Follower滞后太多或失效时，Leader会把它从ISR集合中剔除，当Leader失效时，只有在ISR集合中的副本才有资格被选举为新的Leader</p>
<h4 id="Rebalance"><a href="#Rebalance" class="headerlink" title="Rebalance"></a>Rebalance</h4><p>前提是消费者没有指明分区消费，此时当消费者组里的消费者和分区关系发生变化时，就会触发Rebalance机制，来重新调整消费者和分区的关系</p>
<ul>
<li>Range：通过公式来计算哪个消费者消费哪个分区</li>
<li>轮询：轮流消费</li>
<li>Sticky：先确保原有消费关系不变，再进行调整</li>
</ul>
<h4 id="HW和LEO"><a href="#HW和LEO" class="headerlink" title="HW和LEO"></a>HW和LEO</h4><p>High Watermark，高水位，取一个Partition对应的ISR中最小的LEO（LOG-END-OFFSET）作为HW，Consumer最多只能消费到HW所在的位置。另外每个Replica都有HW，Leader和Follower各自负责更新自己的HW状态。对于Leader新写入的消息，Consumer不能立刻消费，Leader会等待该消息被所有ISR中的Replica同步后更新HW，之后Consumer才能进行消费。这样就保证了如果Leader所在的Broker失效，消息仍然能从新选举出的Leader中获得</p>
<h3 id="JAVA使用Kafka"><a href="#JAVA使用Kafka" class="headerlink" title="JAVA使用Kafka"></a>JAVA使用Kafka</h3><h4 id="引入依赖"><a href="#引入依赖" class="headerlink" title="引入依赖"></a>引入依赖</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0&quot;</span></span></span><br><span class="line"><span class="tag">  <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag">  <span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.example<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>Kafka<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">maven.compiler.source</span>&gt;</span>8<span class="tag">&lt;/<span class="name">maven.compiler.source</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">maven.compiler.target</span>&gt;</span>8<span class="tag">&lt;/<span class="name">maven.compiler.target</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">project.build.sourceEncoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">project.build.sourceEncoding</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka-clients<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.6.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">      <span class="comment">&lt;!--&gt;在SpringBoot中的依赖为&lt;--&gt;</span></span><br><span class="line">      <span class="comment">&lt;!--&gt;&lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt;&lt;--&gt;</span></span><br><span class="line">      <span class="comment">&lt;!--&gt;&lt;artifactId&gt;spring-kafka&lt;/artifactId&gt;&lt;--&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.slf4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>slf4j-simple<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.7.30<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">scope</span>&gt;</span>compile<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--&gt;这个包用来解决Failed to load class &quot;org.slf4j.impl.StaticLoggerBinder&quot;报错&lt;--&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!--&gt;import org.apache.kafka.clients&lt;--&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="Producer-1"><a href="#Producer-1" class="headerlink" title="Producer"></a>Producer</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.dy;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringSerializer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ExecutionException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 创建一个Kafka的生产者类</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyProducer</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> <span class="type">String</span> <span class="variable">TOPIC_NAME</span> <span class="operator">=</span> <span class="string">&quot;my-topic&quot;</span>;  <span class="comment">// 声明要生产的主题名称</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">// 设置参数</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">props</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;43.153.211.186:9092&quot;</span>);</span><br><span class="line">        <span class="comment">// 把发送的Key从字符串序列化为字节数组</span></span><br><span class="line">        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        <span class="comment">// 把发送消息的Value从字符串序列化为字节数组</span></span><br><span class="line">        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建生产者，传入参数</span></span><br><span class="line">        Producer&lt;String, String&gt; producer = <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;&gt;(props);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建消息，Key决定了发往哪个分区，Value是具体发送的消息内容</span></span><br><span class="line">        ProducerRecord&lt;String, String&gt; producerRecord = <span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(TOPIC_NAME, <span class="string">&quot;myKey&quot;</span>, <span class="string">&quot;HelloWallet&quot;</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 同步发送消息，获取消息元数据并输出</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="type">RecordMetadata</span> <span class="variable">recordMetadata</span> <span class="operator">=</span> producer.send(producerRecord).get();  <span class="comment">// 使用get方法获取服务端返回的ACK，如果没有返回则会阻塞</span></span><br><span class="line">            System.out.println(<span class="string">&quot;同步发送结果：&quot;</span> + <span class="string">&quot;topic - &quot;</span> + recordMetadata.topic() +</span><br><span class="line">                    <span class="string">&quot; partition - &quot;</span> + recordMetadata.partition() +</span><br><span class="line">                    <span class="string">&quot; offset - &quot;</span> + recordMetadata.offset());</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e)&#123;  <span class="comment">// 用try-catch驳货异常</span></span><br><span class="line">            e.printStackTrace();</span><br><span class="line">            Thread.sleep(<span class="number">1000</span>);  <span class="comment">// 重试间隔</span></span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="type">RecordMetadata</span> <span class="variable">recordMetadata</span> <span class="operator">=</span> producer.send(producerRecord).get();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e1) &#123;</span><br><span class="line">                <span class="comment">// 重试失败，进行其他处理</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (ExecutionException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 异步发送消息，异步容易产生消息丢失，真正使用时同步用得更多</span></span><br><span class="line">        producer.send(producerRecord, <span class="keyword">new</span> <span class="title class_">Callback</span>() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onCompletion</span><span class="params">(RecordMetadata recordMetadata, Exception e)</span> &#123;</span><br><span class="line">                <span class="keyword">if</span> (e != <span class="literal">null</span>) &#123;</span><br><span class="line">                    System.out.println(<span class="string">&quot;消息发送失败：&quot;</span> + e.getStackTrace());</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (recordMetadata != <span class="literal">null</span>) &#123;</span><br><span class="line">                    System.out.println(<span class="string">&quot;异步发送结果：&quot;</span> + <span class="string">&quot;topic - &quot;</span> + recordMetadata.topic() +</span><br><span class="line">                            <span class="string">&quot; partition - &quot;</span> + recordMetadata.partition() +</span><br><span class="line">                            <span class="string">&quot; offset - &quot;</span> + recordMetadata.offset());</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        Thread.sleep(<span class="number">10000L</span>);  <span class="comment">// 主线程关闭不会打印出来，所以延迟关闭</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 执行后报错could not be established. Broker may not be available.</span></span><br><span class="line"><span class="comment">使用命令sudo lsof -i:9092可以看到localhost:9092 (LISTEN)</span></span><br><span class="line"><span class="comment">先检查防火墙是否开启了9092端口</span></span><br><span class="line"><span class="comment">然后修改server.properties中的</span></span><br><span class="line"><span class="comment">listeners=PLAINTEXT://0.0.0.0:9092</span></span><br><span class="line"><span class="comment">表示监听所有IP的访问</span></span><br><span class="line"><span class="comment">此时重启Kafka</span></span><br><span class="line"><span class="comment">使用命令sudo lsof -i:9092可以看到*:9092 (LISTEN)</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<h4 id="Consumer-1"><a href="#Consumer-1" class="headerlink" title="Consumer"></a>Consumer</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.dy;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecords;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.KafkaConsumer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringDeserializer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.time.Duration;</span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyConsumer</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">String</span> <span class="variable">TOPIC_NAME</span> <span class="operator">=</span> <span class="string">&quot;my-topic&quot;</span>;  <span class="comment">// 想要消费的Topic名称</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">String</span> <span class="variable">CONSUMER_GROUP_NAME</span> <span class="operator">=</span> <span class="string">&quot;testGroup&quot;</span>;  <span class="comment">// 所属的消费者组名称</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">Properties</span> <span class="variable">props</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();  <span class="comment">// 配置信息</span></span><br><span class="line">        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;43.153.211.186:9092&quot;</span>);  <span class="comment">// 服务IP</span></span><br><span class="line">        props.put(ConsumerConfig.GROUP_ID_CONFIG, CONSUMER_GROUP_NAME);  <span class="comment">// 消费者组</span></span><br><span class="line">        <span class="comment">//props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, &quot;false&quot;);  // 是否自动提交offset</span></span><br><span class="line">        <span class="comment">/*默认设置为true，也可以声明自动提交offset的时间间隔</span></span><br><span class="line"><span class="comment">        * props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, &quot;true&quot;);</span></span><br><span class="line"><span class="comment">        * props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, &quot;1000&quot;);*/</span></span><br><span class="line"></span><br><span class="line">        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, <span class="string">&quot;earliest&quot;</span>);</span><br><span class="line">        <span class="comment">/*当消费主体的是一个新消费者组，或者指定offset的消费方式</span></span><br><span class="line"><span class="comment">        * latest：只消费自己启动之后发送到主题的消息</span></span><br><span class="line"><span class="comment">        * earliest：首次启动时从头开始消费，下次启动根据offset继续消费*/</span></span><br><span class="line">        <span class="comment">//consumer.seekToBeginning 配置则会每次都从头开始消费</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//props.put(ConsumerConfig.HEARTBEAT_INTERVAL_MS_CONFIG, 1000);  // Consumer给broker发送心跳的间隔时间</span></span><br><span class="line">        <span class="comment">//props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 10*1000);</span></span><br><span class="line">        <span class="comment">/*Kafka如果超过这个时间没有收到消费者的心跳，就会把消费者踢出消费者组，进行rebalance，将分区分配给其他消费者*/</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, 500);  // 一次poll最大拉取消息的条数，根据消费速度来设置</span></span><br><span class="line">        <span class="comment">//props.put(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG, 30*1000);  // 两次poll间隔超过这个事件，Kafka认为消费能力过弱，将其踢出消费者组</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 把收到的Key从字节数组转化为字符串</span></span><br><span class="line">        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line">        <span class="comment">// 把发送消息的Value从字节数组转化为字符串</span></span><br><span class="line">        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span><br><span class="line"></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> <span class="title class_">KafkaConsumer</span>&lt;String, String&gt;(props);  <span class="comment">// 创建消费者客户端</span></span><br><span class="line">        consumer.subscribe(Arrays.asList(TOPIC_NAME));  <span class="comment">// 订阅主题列表</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = consumer.poll(Duration.ofMillis(<span class="number">1000</span>));  <span class="comment">// 拉取消息的长轮询</span></span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord: consumerRecords) &#123;</span><br><span class="line">                <span class="comment">// 打印消息</span></span><br><span class="line">                System.out.printf(<span class="string">&quot;收到消息：partition = %d， offset = %d， key = %s， value = %s%n&quot;</span>,</span><br><span class="line">                                  consumerRecord.partition(), consumerRecord.offset(), consumerRecord.key(), consumerRecord.value());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="线上问题优化"><a href="#线上问题优化" class="headerlink" title="线上问题优化"></a>线上问题优化</h3><h4 id="防止消息丢失"><a href="#防止消息丢失" class="headerlink" title="防止消息丢失"></a>防止消息丢失</h4><p>Producer：ack设置为-1或all，确保足够多的副本都完成消息同步再返回ACK</p>
<p>Consumer：将自动提交改为手动提交，确保消息被消费后再更新offset</p>
<h4 id="防止消息重复消费"><a href="#防止消息重复消费" class="headerlink" title="防止消息重复消费"></a>防止消息重复消费</h4><p>Producer：当Producer发送消息后，由于网络问题未收到Kafka服务端返回的ACK，则会进行重试，此时服务端就会造成消息重复，如果从Producer端考虑防止，则应该关闭重试机制，但为了确保消息不丢失，又不应该关闭重试，所以应该考虑在Consumer端进行解决</p>
<p>Consumer：当Consumer收到消息后，需要一个机制来确保当前消息与之前已经消费过的消息不重复，可以通过幂等性保证来解决，例如通过主键来判断重复性或使用Redis&#x2F;Zookeeper的分布式锁（主流方案）</p>
<h5 id="幂等性"><a href="#幂等性" class="headerlink" title="幂等性"></a>幂等性</h5><p>在数学中某一元运算为幂等时，其作用在任一元素两次后会和其作用一次的结果相同。在软件工程中，指的是函数&#x2F;接口可以使用相同的参数重复执行，不影响系统的状态也不会对系统造成改变</p>
<p>幂等性保证需要满足三个条件：</p>
<ul>
<li>请求唯一标识，即每一个请求必须有一个唯一标识； </li>
<li>处理唯一标识，即每次处理完请求之后，必须有一个记录标识这个请求被处理过了</li>
<li>逻辑判断处理，即每次接收请求需要进行判断之前是否处理过，也就是根据请求唯一标识查询是否存在处理唯一标识</li>
</ul>
<p>幂等性常见的实现方案有：</p>
<ol>
<li>token机制：针对客户端重复连续多次点击的情况，提交接口需要通过token机制实现防止重复提交，主要流程为：<br>a. 服务端提供生成请求token的接口，在存在幂等问题的业务执行前，向服务器请求获取token，服务器会把token保存到Redis中<br>b. 调用业务接口请求时，把token携带过去，一般放在请求头中<br>c. 服务器判断请求token是否存在于Redis中，存在则表示为第一次请求，这时把Redis中的token删除，继续执行业务；如果判断token不存在于Redis，则表示是重复操作，直接返回重复标记给客户端</li>
<li>数据库索引唯一：往数据库表里插入数据的时候，利用数据库的唯一索引特性来保证唯一性</li>
<li>Redis实现：将唯一序列号作为key存入Redis，在请求处理前先查看key是否存在，不存在则表示为处理过，存在则表示已经处理过</li>
<li>状态机：在业务处理中，通过业务流转状态控制请求的幂等</li>
<li>分布式锁：<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzUyNzgyNzAwNg==&amp;mid=2247484334&amp;idx=1&amp;sn=4429f5810752012233bf8d5718181e2c&amp;scene=21#wechat_redirect">一篇文章</a></li>
</ol>
<h4 id="实现顺序消费"><a href="#实现顺序消费" class="headerlink" title="实现顺序消费"></a>实现顺序消费</h4><p>Producer：ack不能设置为0，关闭重试，使用同步发送，确保消息是顺序发送的</p>
<p>Topic：设置为单一分区，因为Kafka只确保单一分区中的消息有序</p>
<p>Consumer：由于是单一分区，此时同一个消费者组里只能有一个消费者，这个消费者消费到的消息是顺序的</p>
<h4 id="解决消息积压"><a href="#解决消息积压" class="headerlink" title="解决消息积压"></a>解决消息积压</h4><p>Producer的生产速度超过Consumer消费速度，会导致消息积压，进而引发Kafka性能问题或服务崩溃，一般由以下方案：</p>
<ol>
<li>在一个消费者中启动多个线程进行消费，提升单一消费者的消费能力；</li>
<li>在一个或多个服务器上启动多个消费者，提高消费能力；</li>
<li>让一个消费者将积压Topic中的消息发送到另一个新的Topic中，新Topic设置多个分区和多个消费者</li>
</ol>
<h4 id="实现延迟队列"><a href="#实现延迟队列" class="headerlink" title="实现延迟队列"></a>实现延迟队列</h4><p>业务场景：如果订单创建30分钟内没有付款，则需要取消订单。这个业务场景可以通过延时队列来实现</p>
<ul>
<li>创建多个Topic，每个Topic表示延时的间隔<ul>
<li>topic_5s：延时5s后需要执行操作的消费者需要消费的主题</li>
<li>topic_1m：延时1min后需要执行操作的消费者需要消费的主题</li>
<li>topic_30m：延时30min后需要执行操作的消费者需要消费的主题</li>
<li>Producer将消息发送到相应的Topic中，并带上消息的发送时间</li>
</ul>
</li>
<li>消费者订阅相应的Topic，消费时轮询Topic中的消息<ul>
<li>如果消息的发送时间和当前消费时间之差超过预设值，则进行某些操作（如超过30min，则去数据库判断订单是否已付款，如未付款则标注这个订单已取消）</li>
<li>如果未超过预设值，则不消费当前offset及之后的消息</li>
<li>等待一定的时间之后，继续从上次消费截止的offset开始poll消息进行判断</li>
</ul>
</li>
</ul>
<h3 id="KafkaEagle监控平台"><a href="#KafkaEagle监控平台" class="headerlink" title="KafkaEagle监控平台"></a>KafkaEagle监控平台</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载</span></span><br><span class="line">wget https://github.com/smartloli/kafka-eagle-bin/archive/v3.0.1.tar.gz</span><br><span class="line"><span class="comment"># 解压</span></span><br><span class="line">tar -zvxf v3.0.1.tar.gz</span><br><span class="line"><span class="built_in">cd</span> kafka-eagle-bin-3.0.1/</span><br><span class="line">tar -zxvf efak-web-3.0.1-bin.tar.gz </span><br><span class="line"><span class="built_in">mv</span> efak-web-3.0.1 ../../kafka-eagle-web</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置</span></span><br><span class="line">vim /etc/profile</span><br><span class="line"><span class="comment"># 增加KE_HOME和PATH配置</span></span><br><span class="line"><span class="comment"># export KE_HOME=../kafka-eagle-web</span></span><br><span class="line"><span class="comment"># export PATH=$PATH:$KE_HOME/bin</span></span><br><span class="line"><span class="comment"># ke配置文件修改</span></span><br><span class="line">vim conf/system-config.properties</span><br><span class="line"><span class="comment"># Zookeeper相关配置</span></span><br><span class="line"><span class="comment"># efak.zk.cluster.alias=cluster1</span></span><br><span class="line"><span class="comment"># cluster1.zk.list=xxx.xxx.xxx.xxx:2181</span></span><br><span class="line"><span class="comment"># 数据库相关配置，配置为MySQL，在MySQL中创建对应的库</span></span><br><span class="line"><span class="comment"># 主要用来保存Eagle的元数据</span></span><br><span class="line"><span class="comment"># efak.driver=com.mysql.cj.jdbc.Driver</span></span><br><span class="line"><span class="comment"># efak.url=jdbc:mysql://...</span></span><br><span class="line"><span class="comment"># efak.username</span></span><br><span class="line"><span class="comment"># efak.password</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动</span></span><br><span class="line">./ke.sh start</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动时报错The KE_HOME environment variable is not defined correctly.</span></span><br><span class="line"><span class="comment"># 需要重新加载系统配置</span></span><br><span class="line"><span class="comment"># source /etc/profile</span></span><br><span class="line"><span class="comment"># 再次启动报错The JAVA_HOME environment variable is not defined correctly.</span></span><br><span class="line"><span class="comment"># 需要在/etc/profile里配置JAVA_HOME</span></span><br><span class="line"><span class="comment"># 查询JAVA安装路径</span></span><br><span class="line"><span class="comment"># which java</span></span><br><span class="line"><span class="comment"># /usr/bin/java</span></span><br><span class="line"><span class="comment"># ls -lrt /usr/bin/java</span></span><br><span class="line"><span class="comment"># /usr/bin/java -&gt; /etc/alternatives/java</span></span><br><span class="line"><span class="comment"># ls -lrt /etc/alternatives/java</span></span><br><span class="line"><span class="comment"># /etc/alternatives/java -&gt; /usr/lib/jvm/java-11-openjdk-amd64/bin/java</span></span><br><span class="line"><span class="comment"># 设置JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64</span></span><br></pre></td></tr></table></figure>

<h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><h3 id="Flume对接Kafka"><a href="#Flume对接Kafka" class="headerlink" title="Flume对接Kafka"></a>Flume对接Kafka</h3><p>生产环境中，更多的是将数据生产到日志之中，从日志中获取数据，一般使用Flume。如果有多个消费者需要这个数据，则需要一个能够支持动态添加的中间件，也就是Kafka。使用Flume+Kafka，就可以实现一次采集，给多个消费者消费。</p>
<p>Flume不支持副本事件。于是，如果Flume代理的一个节点奔溃了，即使使用了可靠的文件管道方式，你也将丢失这些事件直到你恢复这些磁盘。如果你需要一个高可靠行的管道，那么使用Kafka是个更好的选择。</p>
<p>如果只是想把日志数据存储到HDFS，则可以Flume直接对接HDFS。</p>
<h2 id="Kafka和RabbitMQ的差异"><a href="#Kafka和RabbitMQ的差异" class="headerlink" title="Kafka和RabbitMQ的差异"></a>Kafka和RabbitMQ的差异</h2><ol>
<li>RabbitMQ是一个分布式消息代理，从多个来源收集流式处理数据，然后将其路由到不同的目标进行处理。而Kafka是一个流式处理平台，用于构建实时数据管道和流失处理应用程序，功能要比RabbitMQ复杂；</li>
<li>RabbitMQ中生产者发送并监控消息是否达到目标消费者。而对于Kafka来说，无论消费者是否检索消息，生产者都会向队列发布消息；</li>
<li>RabbitMQ允许生产者使用优先队列升级某些消息，即不按照先入先出的顺序发送，而是按照优先级来处理消息。而Kafka平等对待这些消息；</li>
<li>RabbitMQ中生产者收到消费者发送的ACK后会将消息从队列中删除。而Kafka数据会一直保存到硬盘直到保留期限到期；</li>
<li>在消息传输容量方面，Kafka优于RabbitMQ。</li>
</ol>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Data/" rel="tag"># Data</a>
              <a href="/tags/Kafka/" rel="tag"># Kafka</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/09/05/Flume/" rel="prev" title="Flume">
      <i class="fa fa-chevron-left"></i> Flume
    </a></div>
      <div class="post-nav-item">
    <a href="/2023/03/09/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%94%BB%E7%95%A5/" rel="next" title="个人博客搭建攻略">
      个人博客搭建攻略 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%97%B2%E8%A8%80%E7%A2%8E%E8%AF%AD"><span class="nav-number">1.</span> <span class="nav-text">闲言碎语</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BF%9B%E7%A8%8B%E9%97%B4%E7%9A%84%E9%80%9A%E4%BF%A1%E6%96%B9%E5%BC%8F"><span class="nav-number">2.</span> <span class="nav-text">进程间的通信方式</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%97%A0%E5%90%8D%E7%AE%A1%E9%81%93"><span class="nav-number">2.1.</span> <span class="nav-text">无名管道</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8D%8A%E5%8F%8C%E5%B7%A5"><span class="nav-number">2.1.1.</span> <span class="nav-text">半双工</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%AB%98%E7%BA%A7%E7%AE%A1%E9%81%93"><span class="nav-number">2.2.</span> <span class="nav-text">高级管道</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%89%E5%90%8D%E7%AE%A1%E9%81%93"><span class="nav-number">2.3.</span> <span class="nav-text">有名管道</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97"><span class="nav-number">2.4.</span> <span class="nav-text">消息队列</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BF%A1%E5%8F%B7%E9%87%8F"><span class="nav-number">2.5.</span> <span class="nav-text">信号量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98"><span class="nav-number">2.6.</span> <span class="nav-text">共享内存</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A5%97%E6%8E%A5%E5%AD%97"><span class="nav-number">2.7.</span> <span class="nav-text">套接字</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-1"><span class="nav-number">3.</span> <span class="nav-text">消息队列</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E4%BA%9B%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5"><span class="nav-number">3.1.</span> <span class="nav-text">一些相关概念</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#HTTP%E5%8D%8F%E8%AE%AE"><span class="nav-number">3.1.1.</span> <span class="nav-text">HTTP协议</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#MIME"><span class="nav-number">3.1.2.</span> <span class="nav-text">MIME</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#RCP"><span class="nav-number">3.1.3.</span> <span class="nav-text">RCP</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#TCP-IP"><span class="nav-number">3.1.4.</span> <span class="nav-text">TCP&#x2F;IP</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#SDK"><span class="nav-number">3.1.5.</span> <span class="nav-text">SDK</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E5%88%86%E7%B1%BB"><span class="nav-number">3.2.</span> <span class="nav-text">消息队列的分类</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9C%89Broker%E7%9A%84MQ"><span class="nav-number">3.2.1.</span> <span class="nav-text">有Broker的MQ</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%87%8DTopic"><span class="nav-number">3.2.1.1.</span> <span class="nav-text">重Topic</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%BD%BBTopic"><span class="nav-number">3.2.1.2.</span> <span class="nav-text">轻Topic</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%97%A0Broker%E7%9A%84MQ"><span class="nav-number">3.2.2.</span> <span class="nav-text">无Broker的MQ</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E4%BC%98%E5%8A%BF"><span class="nav-number">3.3.</span> <span class="nav-text">消息队列的优势</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%A8%A1%E5%BC%8F"><span class="nav-number">3.4.</span> <span class="nav-text">消息队列的两种模式</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka"><span class="nav-number">4.</span> <span class="nav-text">Kafka</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="nav-number">4.1.</span> <span class="nav-text">使用场景</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%90%AD%E5%BB%BA"><span class="nav-number">4.2.</span> <span class="nav-text">搭建</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84"><span class="nav-number">4.3.</span> <span class="nav-text">基本架构</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Broker"><span class="nav-number">4.3.1.</span> <span class="nav-text">Broker</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Producer"><span class="nav-number">4.3.2.</span> <span class="nav-text">Producer</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Consumer"><span class="nav-number">4.3.3.</span> <span class="nav-text">Consumer</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Topic"><span class="nav-number">4.3.4.</span> <span class="nav-text">Topic</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Consumer-Group"><span class="nav-number">4.3.5.</span> <span class="nav-text">Consumer Group</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Partition"><span class="nav-number">4.3.6.</span> <span class="nav-text">Partition</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Replica"><span class="nav-number">4.3.7.</span> <span class="nav-text">Replica</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Leader"><span class="nav-number">4.3.8.</span> <span class="nav-text">Leader</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Follower"><span class="nav-number">4.3.9.</span> <span class="nav-text">Follower</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Controller"><span class="nav-number">4.3.10.</span> <span class="nav-text">Controller</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Zookeeper"><span class="nav-number">4.3.11.</span> <span class="nav-text">Zookeeper</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%90%AD%E5%BB%BA%E9%9B%86%E7%BE%A4"><span class="nav-number">4.4.</span> <span class="nav-text">搭建集群</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE"><span class="nav-number">4.5.</span> <span class="nav-text">配置</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#ACK"><span class="nav-number">4.5.1.</span> <span class="nav-text">ACK</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Batch"><span class="nav-number">4.5.2.</span> <span class="nav-text">Batch</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Offset"><span class="nav-number">4.5.3.</span> <span class="nav-text">Offset</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6"><span class="nav-number">4.6.</span> <span class="nav-text">核心机制</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#ISR"><span class="nav-number">4.6.1.</span> <span class="nav-text">ISR</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Rebalance"><span class="nav-number">4.6.2.</span> <span class="nav-text">Rebalance</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#HW%E5%92%8CLEO"><span class="nav-number">4.6.3.</span> <span class="nav-text">HW和LEO</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#JAVA%E4%BD%BF%E7%94%A8Kafka"><span class="nav-number">4.7.</span> <span class="nav-text">JAVA使用Kafka</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BC%95%E5%85%A5%E4%BE%9D%E8%B5%96"><span class="nav-number">4.7.1.</span> <span class="nav-text">引入依赖</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Producer-1"><span class="nav-number">4.7.2.</span> <span class="nav-text">Producer</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Consumer-1"><span class="nav-number">4.7.3.</span> <span class="nav-text">Consumer</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BA%BF%E4%B8%8A%E9%97%AE%E9%A2%98%E4%BC%98%E5%8C%96"><span class="nav-number">4.8.</span> <span class="nav-text">线上问题优化</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%98%B2%E6%AD%A2%E6%B6%88%E6%81%AF%E4%B8%A2%E5%A4%B1"><span class="nav-number">4.8.1.</span> <span class="nav-text">防止消息丢失</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%98%B2%E6%AD%A2%E6%B6%88%E6%81%AF%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9"><span class="nav-number">4.8.2.</span> <span class="nav-text">防止消息重复消费</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%B9%82%E7%AD%89%E6%80%A7"><span class="nav-number">4.8.2.1.</span> <span class="nav-text">幂等性</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0%E9%A1%BA%E5%BA%8F%E6%B6%88%E8%B4%B9"><span class="nav-number">4.8.3.</span> <span class="nav-text">实现顺序消费</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%A7%A3%E5%86%B3%E6%B6%88%E6%81%AF%E7%A7%AF%E5%8E%8B"><span class="nav-number">4.8.4.</span> <span class="nav-text">解决消息积压</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0%E5%BB%B6%E8%BF%9F%E9%98%9F%E5%88%97"><span class="nav-number">4.8.5.</span> <span class="nav-text">实现延迟队列</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#KafkaEagle%E7%9B%91%E6%8E%A7%E5%B9%B3%E5%8F%B0"><span class="nav-number">4.9.</span> <span class="nav-text">KafkaEagle监控平台</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="nav-number">4.10.</span> <span class="nav-text">应用场景</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Flume%E5%AF%B9%E6%8E%A5Kafka"><span class="nav-number">4.11.</span> <span class="nav-text">Flume对接Kafka</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka%E5%92%8CRabbitMQ%E7%9A%84%E5%B7%AE%E5%BC%82"><span class="nav-number">5.</span> <span class="nav-text">Kafka和RabbitMQ的差异</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="西左"
      src="/images/avatar.jpeg">
  <p class="site-author-name" itemprop="name">西左</p>
  <div class="site-description" itemprop="description">自是者不彰。</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">13</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/dangyoo" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;dangyoo" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i></a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">西左</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
